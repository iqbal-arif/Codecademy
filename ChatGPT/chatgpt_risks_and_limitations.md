1. Introduction

---

ChatGPT has great potential to change the way we write, but there can be risks and limitations to using it. From false information to copyright infringement, there are factors to consider before integrating it into our lives.

Though ChatGPT has been trained on massive quantities of data, it is far from perfect. It does not truly think about the words it is producing because it’s a trained language model, not a person. While people have the ability to judge and think about what words we write, ChatGPT merely follows its language model.

For example, large language models rely on word co-occurrence in their training data to guess what is the best thing to say next. (For instance, a word like “autumn” likely has a strong association with the words “leaves”, “pumpkin”, “Halloween”, etc.) So it is able to guess context by word association and not from the meaning of the words. This can lead it to make mistaken associations based on the training data. The limitations of that model and its data make their way into ChatGPT’s output.

When using ChatGPT for personal or business use, it is important to understand these limitations. Misinformation, offensive content, and data breaches are serious threats to people relying on ChatGPT for content. These kinds of issues could cause serious reputational harm or even legal liabilities in the right situation.

Over the course of this lesson, we will be exploring key risks and limitations of using ChatGPT. The next several exercises will go into detail on ChatGPT’s lack of understanding, its misinformation, and its biases.

2. ChatGPT and Misinformation

---

While ChatGPT can be a valuable tool for answering questions and generating text, it also has the potential to spread misinformation, things that aren’t true. ChatGPT does not always provide accurate or truthful responses to certain prompts.

While the internet houses much of the world’s information, not all of that information is true. A language model learning from internet data can quickly pick up inaccuracies, and due to the vast amount of information that is out there, it is not easy to correct all of the false information that ChatGPT “learned”. Any information coming from ChatGPT should be verified before being relied on.

Remember, ChatGPT doesn’t actually understand the information it is writing! ChatGPT isn’t able to understand the nuances of discussions, debates, or even the meaning of words and phrases. It generates the next word it thinks is the most likely to appear after what it has written so far. It does not understand whether the text it is generating is “true”.

While some of ChatGPT’s content may be incorrect due to incorrect training data, sometimes AI will literally make up information. The tendency for large language models like ChatGPT to confidently assert false information in this way is known as hallucination. These made-up statements often occur when ChatGPT is asked to produce very specific information. Lacking nuanced knowledge, it simply produces a response that it deems likely to occur next, regardless of whether that response makes sense.

3. ChatGPT and Disinformation

ChatGPT can sometimes produce wrong information on its own, but it can also be used to produce false information on purpose.

ChatGPT’s ability to quickly produce information makes it a prime target for creating disinformation intended to mislead people. There are people who might intentionally try to get ChatGPT to produce propaganda to support their own causes. Using ChatGPT, people are able to quickly produce massive amounts of information and put it onto the internet. Consider people using ChatGPT to:

    Create many fraudulent positive or negative reviews
    Write many different articles all repeating the same false narrative
    Post many variants of the same comments on people’s videos

By placing overwhelming amounts of content all saying the same thing, people using ChatGPT have the chance to control the narrative around topics of their choosing. Fraudulent content produced by ChatGPT would outpace true content produced by real people.

They can take advantage of people who may believe that ChatGPT is smarter than people because, after all, ChatGPT knows the whole internet.

Researchers are trying to correct these problems within ChatGPT. Over time, ChatGPT has been programmed to limit its ability to generate false or misleading information. However, this remains an unsolved problem.

4. ChatGPT and Bias

---

Another issue stemming from ChatGPT being trained on human information is bias. The internet and literature, which ChatGPT is trained on, contain many harmful biases. By being trained on this information, ChatGPT can replicate these biases in its output.

There are many situations in which these biases can show in ChatGPT responses. Asking ChatGPT to produce descriptions of people in certain fields, or with certain traits can result in stereotypical responses. Many people have found different ways to get ChatGPT to produce biased responses towards certain demographics, including racist, sexist, and bigoted statements.

People have found ways to get ChatGPT to produce content with sentiments like Black people being inferior to white people, as well as women being subservient to men. ChatGPT updates have closed many of the ways to do this, but people continue to find new prompts that get past its safeguards.

ChatGPT producing these kinds of statements is a problem for several reasons. It perpetuates false harmful stereotypes, and, as mentioned in the last exercise, ChatGPT can act as a propaganda machine for bad actors.

Subsequent updates to ChatGPT may reduce these problems, but they will continue to show up in subtle ways. Removing all bias from information is an open problem in creating large language models. Hopefully, new and improved algorithms will continue to reduce the impact of bias in AI systems

5. ChatGPT and Data Security

---

As people use ChatGPT, it collects information from the prompts being used and the people that write them. Where is this data going, how is it being used, and is it secure?

Like any data-heavy application, ChatGPT is at risk for data breaches or misuse of user data. As more and more companies and individuals use ChatGPT, there is a greater need to make sure user data is protected and not misused.

When individuals and business input sensitive information into ChatGPT, they are trusting that ChatGPT is securing their data in a safe and anonymized way. Data breaches of the past have shown us this is not always the case, so it is important to be careful when uploading sensitive information.

Review

---

While ChatGPT has shown tremendous potential for changing the way we work, there are potential risks associated with its use. As with any technology, there is a need for caution and awareness when using ChatGPT or any language model. Some of the potential issues we discussed in this lesson are:

    1. Misinformation: The tendency for ChatGPT to produce incorrect information
    2. Disinformation: The ability for ChatGPT to be used to produce information intended to mislead people
    3. Bias: ChatGPT presenting biases based on the training data it has received
    4. Data Security: The security and privacy issues stemming from the data ChatGPT is collecting

It is important to understand these limitations and to use ChatGPT responsibly to avoid spreading misinformation or causing harm. Encountering these issues with ChatGPT can be a significant liability for a person or company integrating it into their content. There is a need for ongoing development and improvement of ChatGPT to address these risks and limitations.
