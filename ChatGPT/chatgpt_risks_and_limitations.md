1. Introduction

---

ChatGPT has great potential to change the way we write, but there can be risks and limitations to using it. From false information to copyright infringement, there are factors to consider before integrating it into our lives.

Though ChatGPT has been trained on massive quantities of data, it is far from perfect. It does not truly think about the words it is producing because it’s a trained language model, not a person. While people have the ability to judge and think about what words we write, ChatGPT merely follows its language model.

For example, large language models rely on word co-occurrence in their training data to guess what is the best thing to say next. (For instance, a word like “autumn” likely has a strong association with the words “leaves”, “pumpkin”, “Halloween”, etc.) So it is able to guess context by word association and not from the meaning of the words. This can lead it to make mistaken associations based on the training data. The limitations of that model and its data make their way into ChatGPT’s output.

When using ChatGPT for personal or business use, it is important to understand these limitations. Misinformation, offensive content, and data breaches are serious threats to people relying on ChatGPT for content. These kinds of issues could cause serious reputational harm or even legal liabilities in the right situation.

Over the course of this lesson, we will be exploring key risks and limitations of using ChatGPT. The next several exercises will go into detail on ChatGPT’s lack of understanding, its misinformation, and its biases.

2. ChatGPT and Misinformation

---

While ChatGPT can be a valuable tool for answering questions and generating text, it also has the potential to spread misinformation, things that aren’t true. ChatGPT does not always provide accurate or truthful responses to certain prompts.

While the internet houses much of the world’s information, not all of that information is true. A language model learning from internet data can quickly pick up inaccuracies, and due to the vast amount of information that is out there, it is not easy to correct all of the false information that ChatGPT “learned”. Any information coming from ChatGPT should be verified before being relied on.

Remember, ChatGPT doesn’t actually understand the information it is writing! ChatGPT isn’t able to understand the nuances of discussions, debates, or even the meaning of words and phrases. It generates the next word it thinks is the most likely to appear after what it has written so far. It does not understand whether the text it is generating is “true”.

While some of ChatGPT’s content may be incorrect due to incorrect training data, sometimes AI will literally make up information. The tendency for large language models like ChatGPT to confidently assert false information in this way is known as hallucination. These made-up statements often occur when ChatGPT is asked to produce very specific information. Lacking nuanced knowledge, it simply produces a response that it deems likely to occur next, regardless of whether that response makes sense.

3. ChatGPT and Disinformation

ChatGPT can sometimes produce wrong information on its own, but it can also be used to produce false information on purpose.

ChatGPT’s ability to quickly produce information makes it a prime target for creating disinformation intended to mislead people. There are people who might intentionally try to get ChatGPT to produce propaganda to support their own causes. Using ChatGPT, people are able to quickly produce massive amounts of information and put it onto the internet. Consider people using ChatGPT to:

    Create many fraudulent positive or negative reviews
    Write many different articles all repeating the same false narrative
    Post many variants of the same comments on people’s videos

By placing overwhelming amounts of content all saying the same thing, people using ChatGPT have the chance to control the narrative around topics of their choosing. Fraudulent content produced by ChatGPT would outpace true content produced by real people.

They can take advantage of people who may believe that ChatGPT is smarter than people because, after all, ChatGPT knows the whole internet.

Researchers are trying to correct these problems within ChatGPT. Over time, ChatGPT has been programmed to limit its ability to generate false or misleading information. However, this remains an unsolved problem.
