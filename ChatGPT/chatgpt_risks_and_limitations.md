1. Introduction

---

ChatGPT has great potential to change the way we write, but there can be risks and limitations to using it. From false information to copyright infringement, there are factors to consider before integrating it into our lives.

Though ChatGPT has been trained on massive quantities of data, it is far from perfect. It does not truly think about the words it is producing because it’s a trained language model, not a person. While people have the ability to judge and think about what words we write, ChatGPT merely follows its language model.

For example, large language models rely on word co-occurrence in their training data to guess what is the best thing to say next. (For instance, a word like “autumn” likely has a strong association with the words “leaves”, “pumpkin”, “Halloween”, etc.) So it is able to guess context by word association and not from the meaning of the words. This can lead it to make mistaken associations based on the training data. The limitations of that model and its data make their way into ChatGPT’s output.

When using ChatGPT for personal or business use, it is important to understand these limitations. Misinformation, offensive content, and data breaches are serious threats to people relying on ChatGPT for content. These kinds of issues could cause serious reputational harm or even legal liabilities in the right situation.

Over the course of this lesson, we will be exploring key risks and limitations of using ChatGPT. The next several exercises will go into detail on ChatGPT’s lack of understanding, its misinformation, and its biases.
