1. Introduction

---

The ethical issues we have to make decisions about when incorporating generative AI into our work and personal lives can be incredibly subtle and sometimes very easy to overlook. Often, they fall into four different categories:

    1. Ethics of replacing human labor with automation

    Is it ethical to replace humans with AI? Is it sometimes ethical to replace humans with AI? This is important in the context of jobs like customer service and content creation jobs.

    2. Buying or selling AI-generated content

    Art, writing, music, and films all fall under content created in this category.

    3. Using AI for decision-making.

    Can we trust AI to make good and accurate decisions? Examples of this include resume screening and risk assessment algorithms (eg TSA clearance, applications for benefits, risk assessment tools used by the police, etc).

    4. Ethics of using autonomous machines

    This includes more than just autonomous driving and drones. This also includes facial recognition kiosks at airports or credit card machines.

It’s important to think about ethical considerations whenever using or interacting with AI.

2. Automation

---

Automation, the process of replacing human labor with machines or software, has been around for centuries. The first spinning mill, replacing a part of the yarn-making process done by hand for thousands of years, was introduced in the late 1700s.

Over the last several centuries, machines have replaced millions of jobs traditionally done by people. Some of these machines are programmed, and many follow simple procedures, repeating one or several parts of a process.

In more recent years, AI is becoming powerful enough to be integrated into machines that do work. Consider some of the following modern uses of AI:

    1. Manufacturing: Inspecting goods for quality control, predicting when equipment will begin to fail
    2. Logistics: Optimizing delivery routes, supply chain management
    3. Customer Service: Answering common questions and resolving simple issues
    Healthcare: Image analysis and diagnosis

In many cases, AI has been found to do them faster, cheaper, and more accurately than a person. However, in each case, AI is replacing a part of the work done by people and sometimes replacing people’s jobs altogether. Is this tradeoff acceptable?

Consider the following scenario:

    A large shipping company spends millions of dollars on a complex AI-powered logistics system. It is able to route each piece of the shipping process more effectively, reducing shipping times by a third. Human drivers and operators on the new routes are expected to follow the routes exactly, in the time predicted, or face disciplinary action. The company is able to let go of hundreds of full-time logistic experts and hires more engineers to continue to build new tech. Outperforming their competition, the new process causes dozens of small competitors to go out of business. These programs make the company the leader in its space.

Proponents of automation argue this is all a part of doing business and possibly beneficial to those involved. People displaced from jobs might receive training and be placed in different positions! (Unfortunately, this is often not the case.) Customers might receive benefits such as lower prices, lower wait times, or other improved outcomes.

Others might say that the use of proprietary AI systems is an unfair advantage. How is a small business supposed to compete and create its own system? Automation may lead to a loss of human skills and knowledge. As machines and software take over more tasks, fewer humans can perform these tasks, resulting in a loss of expertise and knowledge that is difficult to regain.

The use of AI and automation in business is a complex topic that has caused debate for hundreds of years. It has the potential to displace hundreds of millions of jobs but has also historically caused huge advancements in the way we, or at least some of us, live. Whether it is worth it or not is often left up to the individual to decide.
